# # configs/adapt/mixture_existing_adapter.yaml
# # 混合现有DCT和Frequency适配器的配置文件

# method: adapter_layer # 或者您用于启用适配器的顶层方法名
# # adapt_method_name: mixture_existing_adapter # 如果您有一个专门的顶层方法名

# adapt_kwargs:
#   type: mixture_existing # 对应于模型代码中检查的类型名
#   position: [MlpAdapter, SpatialAdapter] # 在MLP层和注意力层后添加适配器
  
#   # 混合适配器本身的参数
#   gate_noise_factor: 1.0 # 门控噪声因子，用于训练时增加探索
#   aux_loss_coeff: 0.01   # 辅助损失的系数

#   # CosineTopKGate 路由器的参数 (可选，使用默认值)
#   router_kwargs:
#     proj_dim: 128 # 内部投影维度，可以根据in_features调整，例如 in_features // 2 或固定值
#     k: 2          # 选择 top-k 专家，对于混合两个，通常k=1或2（如果允许选多个）
#     init_t: 0.5   # 温度初始化参数

#   # DCT 专家的配置参数 (这些参数会被传递给 DCTAdapter 的构造函数)
#   dct_expert_kwargs:
#     mlp_ratio: 0.25        # DCT专家内部MLP的比例
#     act_layer: gelu
#     adapter_scalar: 0.1   # DCT专家自己的缩放因子
#     dct_kernel_size: 3
#     dct_groups: 1

#   # Frequency 专家的配置参数 (这些参数会被传递给 DCTFrequencyAdapter 的构造函数)
#   freq_expert_kwargs:
#     mlp_ratio: 0.25        # Frequency专家内部MLP的比例
#     act_layer: gelu
#     adapter_scalar: 0.1   # Frequency专家自己的缩放因子
  
#   # 普通Adapter的配置参数
#   adapter_kwargs:
#     mlp_ratio: 0.25        # 普通Adapter内部MLP的比例
#     act_layer: gelu
#     adapter_scalar: 0.1    # 普通Adapter的缩放因子

# configs/adapt/dynamic_mixture.yaml
# 支持动态添加专家的混合适配器配置文件

method: adapter_layer 

adapt_kwargs:
  type: mixture_existing 
  position: [MlpAdapter, SpatialAdapter] # 在MLP层和注意力层后添加适配器
  
  # 混合适配器本身的参数
  gate_noise_factor: 1.0 # 门控噪声因子，用于训练时增加探索
  aux_loss_coeff: 0.01   # 辅助损失的系数

  # 路由器参数
  router_kwargs:
    proj_dim: 128 # 内部投影维度
    k: 2          # 选择 top-k 专家
    init_t: 0.5   # 温度初始化参数

  # 动态专家配置，替代之前的单独专家配置
  experts_config:
    - type: dct     # 专家类型
      name: dct_expert # 专家名称
      kwargs:       # 专家参数
        mlp_ratio: 0.25
        act_layer: gelu
        adapter_scalar: 0.1
        dct_kernel_size: 3
        dct_groups: 1
        
    # - type: frequency # 专家类型
    #   name: freq_expert # 专家名称
    #   kwargs:        # 专家参数
    #     mlp_ratio: 0.25
    #     act_layer: gelu
    #     adapter_scalar: 0.1
        
    - type: adapter  # 普通适配器专家
      name: base_adapter # 专家名称
      kwargs:         # 专家参数
        mlp_ratio: 0.25
        act_layer: gelu
        adapter_scalar: 0.1
